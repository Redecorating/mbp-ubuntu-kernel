From ae58697c8114c393cfdf5da0a1331a61b3766321 Mon Sep 17 00:00:00 2001
From: Sven Peter <sven@svenpeter.dev>
Date: Fri, 1 Jul 2022 17:21:01 +0200
Subject: [PATCH] WIP:/DO-NOT-MERGE: bluetooth

---
 MAINTAINERS                     |    1 +
 drivers/bluetooth/Kconfig       |   12 +
 drivers/bluetooth/Makefile      |    2 +
 drivers/bluetooth/hci_bcm43xx.c | 1938 +++++++++++++++++++++++++++++++
 4 files changed, 1953 insertions(+)
 create mode 100644 drivers/bluetooth/hci_bcm43xx.c

diff --git a/drivers/bluetooth/Kconfig b/drivers/bluetooth/Kconfig
index e307074054553a..2f5ca7bc7c14ce 100644
--- a/drivers/bluetooth/Kconfig
+++ b/drivers/bluetooth/Kconfig
@@ -274,6 +274,18 @@ config BT_HCIBCM203X
 	  Say Y here to compile support for HCI BCM203x devices into the
 	  kernel or say M to compile it as module (bcm203x).
 
+
+config BT_HCIBCM43XX
+	tristate "HCI BCM43xx PCI driver"
+	depends on PCI
+	default m
+	help
+	  Support for Broadcom BCM43xx bluetooth chipsets attached over PCI,
+	  which are usually found in Apple machines.
+
+	  Say Y here to compile support for HCI BCM43xx devices into the
+	  kernel or say M to compile it as module (bcm43xx).
+
 config BT_HCIBPA10X
 	tristate "HCI BPA10x USB driver"
 	depends on USB
diff --git a/drivers/bluetooth/Makefile b/drivers/bluetooth/Makefile
index 3321a8aea4a065..2be16bd3c32c0a 100644
--- a/drivers/bluetooth/Makefile
+++ b/drivers/bluetooth/Makefile
@@ -33,6 +33,8 @@ obj-$(CONFIG_BT_HCIUART_NOKIA)	+= hci_nokia.o
 
 obj-$(CONFIG_BT_HCIRSI)		+= btrsi.o
 
+obj-$(CONFIG_BT_HCIBCM43XX)	+= hci_bcm43xx.o
+
 btmrvl-y			:= btmrvl_main.o
 btmrvl-$(CONFIG_DEBUG_FS)	+= btmrvl_debugfs.o
 
diff --git a/drivers/bluetooth/hci_bcm43xx.c b/drivers/bluetooth/hci_bcm43xx.c
new file mode 100644
index 00000000000000..4910c5dc1af4f7
--- /dev/null
+++ b/drivers/bluetooth/hci_bcm43xx.c
@@ -0,0 +1,1938 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Bluetooth HCI driver for Broadcom 43XX devices attached via PCI
+ *
+ * Copyright (C) The Asahi Linux Contributors
+ *
+ * The (official) terms "completion ring" and "transfer ring" are a bit
+ * misleading:
+ * For transfers from the host to the device an entry is enqueued in the
+ * transfer ring and the device will acknowledge it by enqueueing and entry
+ * in the corresponding completion ring.
+ * For transfer initiated from the device however an entry will be enqueued
+ * inside the completion ring (which has not corresponding entry in the transfer
+ * ring). The transfer ring for this direction has no memory associated but
+ * just a head and tail pointer. The message from the device is acknowledged
+ * by simple advancing the head of the transfer ring and ringing a doorbell.
+ */
+
+// TODO: sort
+#include <linux/acpi.h>
+#include <linux/async.h>
+#include <linux/bitfield.h>
+#include <linux/module.h>
+#include <linux/firmware.h>
+#include <linux/dmi.h>
+#include <linux/of.h>
+#include <linux/firmware.h>
+#include <linux/pci.h>
+#include <linux/msi.h>
+#include <linux/dma-mapping.h>
+#include <linux/completion.h>
+#include <asm/unaligned.h>
+#include <linux/printk.h>
+
+#include <net/bluetooth/bluetooth.h>
+#include <net/bluetooth/hci_core.h>
+
+enum bcm43xx_chip {
+	BCM4377 = 0,
+	BCM4378,
+	BCM4387,
+};
+
+#define BCM4377_DEVICE_ID 0x5fa0
+#define BCM4378_DEVICE_ID 0x5f69
+#define BCM4387_DEVICE_ID 0x5f71
+
+/* vendor-specific config space registers */
+#define BCM43XX_PCIECFG_BAR0_WINDOW0 0x80
+#define BCM43XX_PCIECFG_BAR0_WINDOW1 0x70
+#define BCM43XX_PCIECFG_BAR0_WINDOW4 0x74
+#define BCM43XX_PCIECFG_BAR0_WINDOW5 0x78
+#define BCM43XX_PCIECFG_BAR2_WINDOW 0x84
+
+#define BCM43XX_PCIECFG_BAR0_WINDOW4_DEFAULT 0x18011000
+#define BCM43XX_PCIECFG_BAR2_WINDOW_DEFAULT 0x19000000
+
+#define BCM43XX_PCIECFG_UNK_CTRL 0x88
+
+/* BAR0 */
+#define BCM43XX_BAR0_OTP_OFFSET 0x4120
+#define BCM43XX_OTP_SIZE 0xe0
+#define BCM43XX_OTP_SYS_VENDOR 0x15
+#define BCM43XX_OTP_CIS 0x80
+#define BCM43XX_OTP_VENDOR_HDR 0x00000008
+#define BCM43XX_OTP_MAX_PARAM_LEN 16
+
+#define BCM43XX_BAR0_FW_DOORBELL 0x140
+#define BCM43XX_BAR0_RTI_CONTROL 0x144
+
+#define BCM43XX_BAR0_DOORBELL 0x174
+#define BCM43XX_BAR0_DOORBELL_VALUE GENMASK(31, 16)
+#define BCM43XX_BAR0_DOORBELL_IDX GENMASK(15, 8)
+#define BCM43XX_BAR0_DOORBELL_RING BIT(5)
+
+#define BCM43XX_BAR0_MSI_ADDR_LO 0x580
+#define BCM43XX_BAR0_MSI_ADDR_HI 0x584
+
+#define BCM43XX_BAR0_HOST_WINDOW_LO 0x590
+#define BCM43XX_BAR0_HOST_WINDOW_HI 0x594
+#define BCM43XX_BAR0_HOST_WINDOW_SIZE 0x598
+
+/* BAR2 */
+#define BCM43XX_BAR2_BOOTSTAGE 0x200454
+
+#define BCM43XX_BAR2_FW_LO 0x200478
+#define BCM43XX_BAR2_FW_HI 0x20047c
+#define BCM43XX_BAR2_FW_SIZE 0x200480
+
+#define BCM43XX_BAR2_RTI_MSI_ADDR_LO 0x2004f8
+#define BCM43XX_BAR2_RTI_MSI_ADDR_HI 0x2004fc
+#define BCM43XX_BAR2_RTI_MSI_DATA 0x200500
+
+#define BCM43XX_BAR2_CONTEXT_ADDR_LO 0x20048c
+#define BCM43XX_BAR2_CONTEXT_ADDR_HI 0x200450
+
+#define BCM43XX_BAR2_RTI_STATUS 0x20045c
+#define BCM43XX_BAR2_RTI_WINDOW_LO 0x200494
+#define BCM43XX_BAR2_RTI_WINDOW_HI 0x200498
+#define BCM43XX_BAR2_RTI_WINDOW_SIZE 0x20049c
+
+#define BCM43XX_N_TRANSFER_RINGS 9
+#define BCM43XX_N_COMPLETION_RINGS 7
+
+#define BCM43XX_CIPC_CONTROL_MSG_SIZE 0x34
+#define BCM43XX_CIPC_HCI_PAYLOAD_SIZE 264
+#define BCM43XX_CIPC_SCO_PAYLOAD_SIZE 264
+#define BCM43XX_CIPC_ACL_PAYLOAD_SIZE 0x3f0
+
+#define BCM43XX_MAX_RING_SIZE 256
+
+#define BCM43XX_MSGID_GENERATION GENMASK(15, 8)
+#define BCM43XX_MSGID_ID GENMASK(7, 0)
+
+enum bcm43xx_transfer_ring_id {
+	BCM43XX_XFER_RING_CONTROL = 0,
+	BCM43XX_XFER_RING_HCI_H2D = 1,
+	BCM43XX_XFER_RING_HCI_D2H = 2,
+	BCM43XX_XFER_RING_SCO_H2D = 3,
+	BCM43XX_XFER_RING_SCO_D2H = 4,
+	BCM43XX_XFER_RING_ACL_H2D = 5,
+	BCM43XX_XFER_RING_ACL_D2H = 6,
+};
+
+enum bcm43xx_completion_ring_id {
+	BCM43XX_ACK_RING_CONTROL = 0,
+	BCM43XX_ACK_RING_HCI_ACL = 1,
+	BCM43XX_EVENT_RING_HCI_ACL = 2,
+	BCM43XX_ACK_RING_SCO = 3,
+	BCM43XX_EVENT_RING_SCO = 4,
+};
+
+enum bcm43xx_doorbell {
+	BCM43XX_DOORBELL_CONTROL = 0,
+	BCM43XX_DOORBELL_HCI_H2D = 1,
+	BCM43XX_DOORBELL_HCI_D2H = 2,
+	BCM43XX_DOORBELL_ACL_H2D = 3,
+	BCM43XX_DOORBELL_ACL_D2H = 4,
+	BCM43XX_DOORBELL_SCO = 6,
+};
+
+struct bcm43xx_xfer_ring_entry {
+#define BCM43XX_XFER_RING_FLAG_PAYLOAD_MAPPED BIT(0)
+#define BCM43XX_XFER_RING_FLAG_PAYLOAD_IN_FOOTER BIT(1)
+	u8 flags;
+	__le16 len;
+	u8 _unk0;
+	__le64 payload;
+	__le16 id;
+	u8 _unk1[2];
+} __packed;
+static_assert(sizeof(struct bcm43xx_xfer_ring_entry) == 0x10);
+
+struct bcm43xx_completion_ring_entry {
+	u8 flags;
+	u8 _unk0;
+	__le16 ring_id;
+	__le16 msg_id;
+	__le32 len;
+	u8 _unk1[6];
+} __packed;
+static_assert(sizeof(struct bcm43xx_completion_ring_entry) == 0x10);
+
+enum bcm43xx_control_message_type {
+	BCM43XX_CONTROL_MSG_CREATE_XFER_RING = 1,
+	BCM43XX_CONTROL_MSG_CREATE_COMPLETION_RING = 2,
+	BCM43XX_CONTROL_MSG_DESTROY_XFER_RING = 3,
+	BCM43XX_CONTROL_MSG_DESTROY_COMPLETION_RING = 4,
+	// BCM43XX_CONTROL_MSG_ABORT_CMDQ = 5,
+};
+
+struct bcm43xx_create_completion_ring_msg {
+	u8 msg_type;
+	u8 header_size;
+	u8 footer_size;
+	u8 _unk0;
+	__le16 id;
+	__le16 id_again;
+	__le64 ring_iova;
+	__le16 n_elements;
+	__le32 unk;
+	u8 _unk1[6];
+	__le16 msi;
+	__le16 intmod_delay;
+	__le32 intmod_bytes;
+	__le16 accum_delay;
+	__le32 accum_bytes;
+	u8 _unk2[10];
+} __packed;
+static_assert(sizeof(struct bcm43xx_create_completion_ring_msg) ==
+	      BCM43XX_CIPC_CONTROL_MSG_SIZE);
+
+struct bcm43xx_destroy_completion_ring_msg {
+	u8 msg_type;
+	u8 _pad0;
+	__le16 ring_id;
+	u8 _pad1[48];
+} __packed;
+static_assert(sizeof(struct bcm43xx_destroy_completion_ring_msg) ==
+	      BCM43XX_CIPC_CONTROL_MSG_SIZE);
+
+struct bcm43xx_create_transfer_ring_msg {
+	u8 msg_type;
+	u8 header_size;
+	u8 footer_size;
+	u8 _unk0;
+	__le16 ring_id;
+	__le16 ring_id_again;
+	__le64 ring_iova;
+	u8 _unk1[8];
+	__le16 n_elements;
+	__le16 completion_ring_id;
+	__le16 doorbell;
+#define BCM43XX_XFER_RING_FLAG_VIRTUAL BIT(7)
+#define BCM43XX_XFER_RING_FLAG_SYNC BIT(8)
+	__le16 flags;
+	u8 _unk2[20];
+} __packed;
+static_assert(sizeof(struct bcm43xx_create_transfer_ring_msg) ==
+	      BCM43XX_CIPC_CONTROL_MSG_SIZE);
+
+struct bcm43xx_destroy_transfer_ring_msg {
+	u8 msg_type;
+	u8 _pad0;
+	__le16 ring_id;
+	u8 _pad1[48];
+} __packed;
+static_assert(sizeof(struct bcm43xx_destroy_transfer_ring_msg) ==
+	      BCM43XX_CIPC_CONTROL_MSG_SIZE);
+
+struct bcm43xx_context {
+	__le16 version;
+	__le16 size;
+	__le32 enabled_caps;
+
+	/* queue heads and tails */
+	__le64 per_info_addr;
+	__le64 completion_ring_heads_addr;
+	__le64 xfer_ring_tails_addr;
+	__le64 completion_ring_tails_addr;
+	__le64 xfer_ring_heads_addr;
+	__le16 n_completion_rings;
+	__le16 n_xfer_rings;
+
+	/* control ring configuration */
+	__le64 control_completion_ring_addr;
+	__le64 control_xfer_ring_addr;
+	__le16 control_xfer_ring_n_entries;
+	__le16 control_completion_ring_n_entries;
+	__le16 control_xfer_ring_doorbell;
+	__le16 control_completion_ring_doorbell;
+	__le16 control_xfer_ring_msi;
+	__le16 control_completion_ring_msi;
+	u8 control_xfer_ring_header_size;
+	u8 control_xfer_ring_footer_size;
+	u8 control_completion_ring_header_size;
+	u8 control_completion_ring_footer_size;
+
+	__le16 _unk0; // inPlaceComp and oOOComp
+	__le16 _unk1; // piMsi -> interrupt for new perInfo data?
+
+	__le64 scratch_pad;
+	__le32 scratch_pad_size;
+
+	__le32 res;
+} __packed;
+static_assert(sizeof(struct bcm43xx_context) == 0x68);
+
+struct bcm43xx_hci_send_calibration_cmd {
+	u8 unk;
+	__le16 blocks_left;
+	u8 data[0xe6];
+} __packed;
+
+struct bcm43xx_hci_send_ptb_cmd {
+	__le16 blocks_left;
+	u8 data[0xcf];
+} __packed;
+
+struct bcm43xx_ring_state {
+	__le16 completion_ring_head[BCM43XX_N_COMPLETION_RINGS];
+	__le16 completion_ring_tail[BCM43XX_N_COMPLETION_RINGS];
+	__le16 xfer_ring_head[BCM43XX_N_TRANSFER_RINGS];
+	__le16 xfer_ring_tail[BCM43XX_N_TRANSFER_RINGS];
+};
+
+struct bcm43xx_transfer_ring {
+	enum bcm43xx_transfer_ring_id ring_id;
+	enum bcm43xx_doorbell doorbell;
+	u16 payload_size;
+	u8 completion_ring;
+	u16 n_entries;
+	u8 generation;
+
+	bool sync;
+	bool virtual;
+	bool allow_wait;
+	bool enabled;
+
+	void *ring;
+	dma_addr_t ring_dma;
+
+	struct completion **events;
+	DECLARE_BITMAP(msgids, BCM43XX_MAX_RING_SIZE);
+	spinlock_t lock;
+};
+
+struct bcm43xx_completion_ring {
+	enum bcm43xx_completion_ring_id ring_id;
+	u16 payload_size;
+	u16 delay;
+	u16 n_entries;
+	bool enabled;
+
+	u16 head;
+	u16 tail;
+
+	void *ring;
+	dma_addr_t ring_dma;
+
+	unsigned long transfer_rings;
+};
+
+struct bcm43xx_data;
+
+struct bcm43xx_hw {
+	const char *name;
+
+	u32 bar0_window0;
+	u32 bar0_window1;
+	u32 bar0_window5;
+
+	bool has_bar0_window5;
+	bool m2m_reset_on_ss_reset_disabled;
+
+	int (*send_calibration)(struct bcm43xx_data *bcm43xx);
+};
+
+struct bcm43xx_data {
+	struct pci_dev *pdev;
+	struct hci_dev *hdev;
+
+	void __iomem *bar0;
+	void __iomem *bar2;
+
+	const struct bcm43xx_hw *hw;
+
+	const void *taurus_cal_blob;
+	int taurus_cal_size;
+	const void *taurus_beamforming_cal_blob;
+	int taurus_beamforming_cal_size;
+
+	char stepping[BCM43XX_OTP_MAX_PARAM_LEN];
+	char vendor[BCM43XX_OTP_MAX_PARAM_LEN];
+	const char *board_type;
+
+	struct completion event;
+
+	int irq;
+
+	struct bcm43xx_context *ctx;
+	dma_addr_t ctx_dma;
+
+	struct bcm43xx_ring_state *ring_state;
+	dma_addr_t ring_state_dma;
+
+	/*
+	 * The HCI and ACL rings have to be merged because this structure is
+	 * hardcoded in the firmware.
+	 */
+	struct bcm43xx_completion_ring control_ack_ring;
+	struct bcm43xx_completion_ring hci_acl_ack_ring;
+	struct bcm43xx_completion_ring hci_acl_event_ring;
+	struct bcm43xx_completion_ring sco_ack_ring;
+	struct bcm43xx_completion_ring sco_event_ring;
+
+	struct bcm43xx_transfer_ring control_h2d_ring;
+	struct bcm43xx_transfer_ring hci_h2d_ring;
+	struct bcm43xx_transfer_ring hci_d2h_ring;
+	struct bcm43xx_transfer_ring sco_h2d_ring;
+	struct bcm43xx_transfer_ring sco_d2h_ring;
+	struct bcm43xx_transfer_ring acl_h2d_ring;
+	struct bcm43xx_transfer_ring acl_d2h_ring;
+};
+
+static void bcm43xx_ring_doorbell(struct bcm43xx_data *bcm43xx, u8 doorbell,
+				  u16 val)
+{
+	u32 db = 0;
+
+	db |= FIELD_PREP(BCM43XX_BAR0_DOORBELL_VALUE, val);
+	db |= FIELD_PREP(BCM43XX_BAR0_DOORBELL_IDX, doorbell);
+	db |= BCM43XX_BAR0_DOORBELL_RING;
+
+	dev_dbg(&bcm43xx->pdev->dev, "write %d to doorbell #%d (0x%x)\n", val,
+		doorbell, db);
+	iowrite32(db, bcm43xx->bar0 + BCM43XX_BAR0_DOORBELL);
+}
+
+static void bcm43xx_handle_event(struct bcm43xx_data *bcm43xx,
+				 struct bcm43xx_transfer_ring *ring, u8 type,
+				 void *payload, size_t len)
+{
+	struct sk_buff *skb;
+	u16 head;
+	unsigned long flags;
+
+	spin_lock_irqsave(&ring->lock, flags);
+	if (!ring->enabled) {
+		dev_warn(&bcm43xx->pdev->dev,
+			 "event for disabled transfer ring %d\n",
+			 ring->ring_id);
+		goto unlock;
+	}
+
+	skb = bt_skb_alloc(len, GFP_ATOMIC);
+	if (!skb)
+		goto unlock;
+
+	memcpy(skb_put(skb, len), payload, len);
+	hci_skb_pkt_type(skb) = type;
+
+	// TODO: check error?
+	hci_recv_frame(bcm43xx->hdev, skb);
+
+	head = le16_to_cpu(bcm43xx->ring_state->xfer_ring_head[ring->ring_id]);
+	head = (head + 1) % ring->n_entries;
+	bcm43xx->ring_state->xfer_ring_head[ring->ring_id] = cpu_to_le16(head);
+
+	bcm43xx_ring_doorbell(bcm43xx, ring->doorbell, head);
+
+unlock:
+	spin_unlock_irqrestore(&ring->lock, flags);
+}
+
+static void bcm43xx_handle_ack(struct bcm43xx_data *bcm43xx,
+			       struct bcm43xx_transfer_ring *ring,
+			       u16 raw_msgid)
+{
+	unsigned long flags;
+	u8 generation = FIELD_GET(BCM43XX_MSGID_GENERATION, raw_msgid);
+	u8 msgid = FIELD_GET(BCM43XX_MSGID_ID, raw_msgid);
+
+	spin_lock_irqsave(&ring->lock, flags);
+
+	if (generation != ring->generation) {
+		dev_warn(
+			&bcm43xx->pdev->dev,
+			"invalid message generation %d should be %d in ack for ring %d\n",
+			generation, ring->generation, ring->ring_id);
+		goto unlock;
+	}
+
+	if (msgid > ring->n_entries) {
+		dev_warn(&bcm43xx->pdev->dev,
+			 "invalid message id in ack for ring %d: %d > %d\n",
+			 ring->ring_id, msgid, ring->n_entries);
+		goto unlock;
+	}
+
+	if (!test_bit(msgid, ring->msgids)) {
+		dev_warn(
+			&bcm43xx->pdev->dev,
+			"invalid message id in ack for ring %d: %d is not used\n",
+			ring->ring_id, msgid);
+		goto unlock;
+	}
+
+	if (ring->allow_wait && ring->events[msgid]) {
+		complete(ring->events[msgid]);
+		ring->events[msgid] = NULL;
+	}
+
+	bitmap_release_region(ring->msgids, msgid, ring->n_entries);
+
+unlock:
+	spin_unlock_irqrestore(&ring->lock, flags);
+}
+
+static void bcm43xx_handle_completion(struct bcm43xx_data *bcm43xx,
+				      struct bcm43xx_completion_ring *ring,
+				      u16 pos)
+{
+	struct bcm43xx_completion_ring_entry *entry;
+	u16 msg_id, transfer_ring;
+	size_t entry_size, data_len;
+	void *data;
+
+	if (pos >= ring->n_entries) {
+		dev_warn(&bcm43xx->pdev->dev, "invalid pos: %d\n", pos);
+		return;
+	}
+
+	entry_size = sizeof(*entry) + ring->payload_size;
+	entry = ring->ring + pos * entry_size;
+	data = ring->ring + pos * entry_size + sizeof(*entry);
+	data_len = le32_to_cpu(entry->len);
+	msg_id = le16_to_cpu(entry->msg_id);
+	transfer_ring = le16_to_cpu(entry->ring_id);
+
+	if ((ring->transfer_rings & BIT(transfer_ring)) == 0) {
+		dev_warn(
+			&bcm43xx->pdev->dev,
+			"invalid entry at offset %d for transfer ring %d in completion ring %d\n",
+			pos, transfer_ring, ring->ring_id);
+		return;
+	}
+
+	dev_dbg(&bcm43xx->pdev->dev,
+		"entry in completion ring %d for transfer ring %d with msg_id %d\n",
+		ring->ring_id, transfer_ring, msg_id);
+
+	switch (transfer_ring) {
+	case BCM43XX_XFER_RING_CONTROL:
+		bcm43xx_handle_ack(bcm43xx, &bcm43xx->control_h2d_ring, msg_id);
+		break;
+	case BCM43XX_XFER_RING_HCI_H2D:
+		bcm43xx_handle_ack(bcm43xx, &bcm43xx->hci_h2d_ring, msg_id);
+		break;
+	case BCM43XX_XFER_RING_HCI_D2H:
+		bcm43xx_handle_event(bcm43xx, &bcm43xx->hci_d2h_ring,
+				     HCI_EVENT_PKT, data, data_len);
+		break;
+	case BCM43XX_XFER_RING_SCO_H2D:
+		bcm43xx_handle_ack(bcm43xx, &bcm43xx->sco_h2d_ring, msg_id);
+		break;
+	case BCM43XX_XFER_RING_SCO_D2H:
+		bcm43xx_handle_event(bcm43xx, &bcm43xx->sco_d2h_ring,
+				     HCI_SCODATA_PKT, data, data_len);
+		break;
+	case BCM43XX_XFER_RING_ACL_H2D:
+		bcm43xx_handle_ack(bcm43xx, &bcm43xx->acl_h2d_ring, msg_id);
+		break;
+	case BCM43XX_XFER_RING_ACL_D2H:
+		bcm43xx_handle_event(bcm43xx, &bcm43xx->acl_d2h_ring,
+				     HCI_ACLDATA_PKT, data, data_len);
+		break;
+	default:
+		dev_err(&bcm43xx->pdev->dev,
+			"entry in completion ring %d for unknown transfer ring %d with msg_id %d\n",
+			ring->ring_id, transfer_ring, msg_id);
+	}
+}
+
+static void bcm43xx_poll_completion_ring(struct bcm43xx_data *bcm43xx,
+					 struct bcm43xx_completion_ring *ring)
+{
+	u16 tail;
+	__le16 *heads = bcm43xx->ring_state->completion_ring_head;
+	__le16 *tails = bcm43xx->ring_state->completion_ring_tail;
+
+	if (!ring->enabled)
+		return;
+
+	tail = le16_to_cpu(tails[ring->ring_id]);
+	dev_dbg(&bcm43xx->pdev->dev,
+		"completion ring #%d: head: %d, tail: %d\n", ring->ring_id,
+		le16_to_cpu(heads[ring->ring_id]), tail);
+
+	while (tail != le16_to_cpu(READ_ONCE(heads[ring->ring_id]))) {
+		/*
+		 * ensure the CPU doesn't speculate through the comparison.
+		 * otherwise it might already read the (empty) queue entry
+		 * before the updated head has been loaded and checked.
+		 */
+		dma_rmb();
+
+		bcm43xx_handle_completion(bcm43xx, ring, tail);
+
+		tail = (tail + 1) % ring->n_entries;
+		tails[ring->ring_id] = cpu_to_le16(tail);
+	}
+}
+
+static irqreturn_t bcm43xx_irq(int irq, void *data)
+{
+	struct bcm43xx_data *bcm43xx = data;
+
+	dev_dbg(&bcm43xx->pdev->dev, "interrupt\n");
+
+	complete(&bcm43xx->event);
+
+	bcm43xx_poll_completion_ring(bcm43xx, &bcm43xx->control_ack_ring);
+	bcm43xx_poll_completion_ring(bcm43xx, &bcm43xx->hci_acl_event_ring);
+	bcm43xx_poll_completion_ring(bcm43xx, &bcm43xx->hci_acl_ack_ring);
+	bcm43xx_poll_completion_ring(bcm43xx, &bcm43xx->sco_ack_ring);
+	bcm43xx_poll_completion_ring(bcm43xx, &bcm43xx->sco_event_ring);
+
+	return IRQ_HANDLED;
+}
+
+static int bcm43xx_enqueue(struct bcm43xx_data *bcm43xx,
+			   struct bcm43xx_transfer_ring *ring, void *data,
+			   size_t len, bool wait)
+{
+	unsigned long flags;
+	struct bcm43xx_xfer_ring_entry *entry;
+	size_t offset;
+	u16 head, tail, new_head;
+	u16 raw_msgid;
+	int ret, msgid;
+	DECLARE_COMPLETION_ONSTACK(event);
+
+	// TODO: just dma_alloc_coherent and BCM43XX_XFER_RING_FLAG_MAPPED
+	// probably required for large ACL packets
+	if (len > ring->payload_size)
+		return -EINVAL;
+	if (wait && !ring->allow_wait)
+		return -EINVAL;
+	if (ring->virtual)
+		return -EINVAL;
+
+	spin_lock_irqsave(&ring->lock, flags);
+
+	head = le16_to_cpu(bcm43xx->ring_state->xfer_ring_head[ring->ring_id]);
+
+	/* tail is changed using DMA; prevent stale reads */
+	dma_rmb();
+	tail = le16_to_cpu(bcm43xx->ring_state->xfer_ring_tail[ring->ring_id]);
+
+	new_head = (head + 1) % ring->n_entries;
+
+	if (new_head == tail) {
+		ret = -EINVAL;
+		goto out;
+	}
+
+	msgid = bitmap_find_free_region(ring->msgids, ring->n_entries, 0);
+	if (msgid < 0) {
+		ret = -EINVAL;
+		goto out;
+	}
+
+	raw_msgid = FIELD_PREP(BCM43XX_MSGID_GENERATION, ring->generation);
+	raw_msgid |= FIELD_PREP(BCM43XX_MSGID_ID, msgid);
+
+	offset = head * (sizeof(*entry) + ring->payload_size);
+	entry = ring->ring + offset;
+
+	memset(entry, 0, sizeof(*entry));
+	entry->id = cpu_to_le16(raw_msgid);
+	entry->len = cpu_to_le16(len);
+	entry->flags = BCM43XX_XFER_RING_FLAG_PAYLOAD_IN_FOOTER;
+	memcpy(ring->ring + offset + sizeof(*entry), data, len);
+
+	if (wait)
+		ring->events[msgid] = &event;
+
+	dev_dbg(&bcm43xx->pdev->dev,
+		"updating head for transfer queue #%d to %d\n", ring->ring_id,
+		new_head);
+	bcm43xx->ring_state->xfer_ring_head[ring->ring_id] =
+		cpu_to_le16(new_head);
+
+	// TODO: check if this is actually correct for sync rings
+	if (!ring->sync)
+		bcm43xx_ring_doorbell(bcm43xx, ring->doorbell, new_head);
+	ret = 0;
+
+out:
+	spin_unlock_irqrestore(&ring->lock, flags);
+
+	if (ret == 0 && wait) {
+		ret = wait_for_completion_interruptible_timeout(&event, 1000);
+		if (ret == 0)
+			ret = -ETIMEDOUT;
+		else if (ret > 0)
+			ret = 0;
+
+		spin_lock_irqsave(&ring->lock, flags);
+		ring->events[msgid] = NULL;
+		spin_unlock_irqrestore(&ring->lock, flags);
+	}
+
+	return ret;
+}
+
+static int bcm43xx_create_completion_ring(struct bcm43xx_data *bcm43xx,
+					  struct bcm43xx_completion_ring *ring)
+{
+	struct bcm43xx_create_completion_ring_msg msg;
+	int ret;
+
+	if (ring->enabled) {
+		dev_warn(&bcm43xx->pdev->dev, "ring already enabled\n");
+		return 0;
+	}
+
+	memset(ring->ring, 0,
+	       ring->n_entries * (sizeof(struct bcm43xx_completion_ring_entry) +
+				  ring->payload_size));
+	memset(&msg, 0, sizeof(msg));
+	msg.msg_type = BCM43XX_CONTROL_MSG_CREATE_COMPLETION_RING;
+	msg.id = cpu_to_le16(ring->ring_id);
+	msg.id_again = cpu_to_le16(ring->ring_id);
+	msg.ring_iova = cpu_to_le64(ring->ring_dma);
+	msg.n_elements = cpu_to_le16(ring->n_entries);
+	msg.intmod_bytes = cpu_to_le32(0xffffffff);
+	msg.unk = cpu_to_le32(0xffffffff);
+	msg.intmod_delay = cpu_to_le16(ring->delay);
+	msg.footer_size = ring->payload_size / 4;
+
+	ret = bcm43xx_enqueue(bcm43xx, &bcm43xx->control_h2d_ring, &msg,
+			      sizeof(msg), true);
+	if (!ret)
+		ring->enabled = true;
+
+	return ret;
+}
+
+static int bcm43xx_destroy_completion_ring(struct bcm43xx_data *bcm43xx,
+					   struct bcm43xx_completion_ring *ring)
+{
+	struct bcm43xx_destroy_completion_ring_msg msg;
+	int ret;
+
+	memset(&msg, 0, sizeof(msg));
+	msg.msg_type = BCM43XX_CONTROL_MSG_DESTROY_COMPLETION_RING;
+	msg.ring_id = cpu_to_le16(ring->ring_id);
+
+	ret = bcm43xx_enqueue(bcm43xx, &bcm43xx->control_h2d_ring, &msg,
+			      sizeof(msg), true);
+	if (ret)
+		dev_warn(&bcm43xx->pdev->dev,
+			 "failed to destroy completion ring %d\n",
+			 ring->ring_id);
+
+	ring->enabled = false;
+	return ret;
+}
+
+static int bcm43xx_create_transfer_ring(struct bcm43xx_data *bcm43xx,
+					struct bcm43xx_transfer_ring *ring)
+{
+	struct bcm43xx_create_transfer_ring_msg msg;
+	u16 flags = 0;
+	int ret;
+	unsigned long spinlock_flags;
+
+	if (ring->virtual)
+		flags |= BCM43XX_XFER_RING_FLAG_VIRTUAL;
+	if (ring->sync)
+		flags |= BCM43XX_XFER_RING_FLAG_SYNC;
+
+	spin_lock_irqsave(&ring->lock, spinlock_flags);
+	memset(&msg, 0, sizeof(msg));
+	msg.msg_type = BCM43XX_CONTROL_MSG_CREATE_XFER_RING;
+	msg.ring_id = cpu_to_le16(ring->ring_id);
+	msg.ring_id_again = cpu_to_le16(ring->ring_id);
+	msg.ring_iova = cpu_to_le64(ring->ring_dma);
+	msg.n_elements = cpu_to_le16(ring->n_entries);
+	msg.completion_ring_id = cpu_to_le16(ring->completion_ring);
+	msg.doorbell = cpu_to_le16(ring->doorbell);
+	msg.flags = cpu_to_le16(flags);
+	msg.footer_size = ring->payload_size / 4;
+
+	bcm43xx->ring_state->xfer_ring_head[ring->ring_id] = 0;
+	bcm43xx->ring_state->xfer_ring_tail[ring->ring_id] = 0;
+	ring->generation++;
+	spin_unlock_irqrestore(&ring->lock, spinlock_flags);
+
+	ret = bcm43xx_enqueue(bcm43xx, &bcm43xx->control_h2d_ring, &msg,
+			      sizeof(msg), true);
+
+	spin_lock_irqsave(&ring->lock, spinlock_flags);
+	/* this primes the device->host side */
+	if (ring->virtual) {
+		bcm43xx->ring_state->xfer_ring_head[ring->ring_id] = 0xf;
+		bcm43xx_ring_doorbell(bcm43xx, ring->doorbell, 0xf);
+	}
+
+	ring->enabled = true;
+	spin_unlock_irqrestore(&ring->lock, spinlock_flags);
+
+	return ret;
+}
+
+static int bcm43xx_destroy_transfer_ring(struct bcm43xx_data *bcm43xx,
+					 struct bcm43xx_transfer_ring *ring)
+{
+	struct bcm43xx_destroy_transfer_ring_msg msg;
+	int ret;
+
+	memset(&msg, 0, sizeof(msg));
+	msg.msg_type = BCM43XX_CONTROL_MSG_DESTROY_XFER_RING;
+	msg.ring_id = cpu_to_le16(ring->ring_id);
+
+	ret = bcm43xx_enqueue(bcm43xx, &bcm43xx->control_h2d_ring, &msg,
+			      sizeof(msg), true);
+	if (ret)
+		dev_warn(&bcm43xx->pdev->dev,
+			 "failed to destroy transfer ring %d\n", ring->ring_id);
+
+	ring->enabled = false;
+	return ret;
+}
+
+static int bcm43xx_send_calibration(struct bcm43xx_data *bcm43xx,
+				    const void *cal_blob, size_t cal_blob_size)
+{
+	struct bcm43xx_hci_send_calibration_cmd cmd;
+	struct sk_buff *skb;
+	off_t done = 0;
+	size_t left = cal_blob_size;
+	u16 blocks_left;
+	int ret;
+
+	if (!cal_blob) {
+		dev_err(&bcm43xx->pdev->dev,
+			"no calibration data available.\n");
+		return -ENOENT;
+	}
+
+	blocks_left = DIV_ROUND_UP(left, sizeof(cmd.data)) - 1;
+
+	while (left) {
+		size_t transfer_len = min(left, sizeof(cmd.data));
+
+		memset(&cmd, 0, sizeof(cmd));
+		cmd.unk = 0x03;
+		cmd.blocks_left = cpu_to_le16(blocks_left);
+		memcpy(cmd.data, cal_blob + done, transfer_len);
+
+		dev_dbg(&bcm43xx->pdev->dev,
+			"btbcmpci: sending calibration chunk; left (chunks): %d, left(bytes): %zu\n",
+			cmd.blocks_left, left);
+
+		skb = __hci_cmd_sync(bcm43xx->hdev, 0xfd97, sizeof(cmd), &cmd,
+				     HCI_INIT_TIMEOUT);
+		if (IS_ERR(skb)) {
+			ret = PTR_ERR(skb);
+			dev_err(&bcm43xx->pdev->dev,
+				"btbcmpci: send calibration failed (%d)", ret);
+			return ret;
+		}
+		kfree_skb(skb);
+
+		blocks_left--;
+		left -= transfer_len;
+		done += transfer_len;
+	}
+
+	return 0;
+}
+
+static int bcm43xx_bcm4378_send_calibration(struct bcm43xx_data *bcm43xx)
+{
+	if (strcmp(bcm43xx->stepping, "b1") == 0)
+		return bcm43xx_send_calibration(
+			bcm43xx, bcm43xx->taurus_beamforming_cal_blob,
+			bcm43xx->taurus_beamforming_cal_size);
+	else
+		return bcm43xx_send_calibration(bcm43xx,
+						bcm43xx->taurus_cal_blob,
+						bcm43xx->taurus_cal_size);
+}
+
+static int bcm43xx_bcm4387_send_calibration(struct bcm43xx_data *bcm43xx)
+{
+	if (strcmp(bcm43xx->stepping, "c2") == 0)
+		return bcm43xx_send_calibration(
+			bcm43xx, bcm43xx->taurus_beamforming_cal_blob,
+			bcm43xx->taurus_beamforming_cal_size);
+	else
+		return bcm43xx_send_calibration(bcm43xx,
+						bcm43xx->taurus_cal_blob,
+						bcm43xx->taurus_cal_size);
+}
+
+static const struct firmware *bcm43xx_request_blob(struct bcm43xx_data *bcm43xx,
+						   const char *suffix)
+{
+	const struct firmware *fw;
+	char name[256];
+	int ret;
+
+	snprintf(name, sizeof(name), "brcmbt%s%s-%s-%s.%s", bcm43xx->hw->name,
+		 bcm43xx->stepping, bcm43xx->board_type, bcm43xx->vendor,
+		 suffix);
+	dev_info(&bcm43xx->pdev->dev, "Trying to load '%s'", name);
+
+	ret = request_firmware(&fw, name, &bcm43xx->pdev->dev);
+	if (!ret)
+		return fw;
+
+	snprintf(name, sizeof(name), "brcmbt%s%s-%s.%s", bcm43xx->hw->name,
+		 bcm43xx->stepping, bcm43xx->board_type, suffix);
+	ret = request_firmware(&fw, name, &bcm43xx->pdev->dev);
+	dev_info(&bcm43xx->pdev->dev, "Trying to load '%s'", name);
+	if (!ret)
+		return fw;
+
+	dev_err(&bcm43xx->pdev->dev, "Unable to load '%s' blob", suffix);
+	return NULL;
+}
+
+static int bcm43xx_send_ptb(struct bcm43xx_data *bcm43xx)
+{
+	const struct firmware *fw;
+	struct bcm43xx_hci_send_ptb_cmd cmd;
+	struct sk_buff *skb;
+	off_t done = 0;
+	size_t left;
+	u16 blocks_left;
+	int ret = 0;
+
+	fw = bcm43xx_request_blob(bcm43xx, "ptb");
+	if (!fw) {
+		dev_err(&bcm43xx->pdev->dev,
+			"btbcmpci: failed to load PTB data");
+		return -ENOENT;
+	}
+
+	left = fw->size;
+	blocks_left = DIV_ROUND_UP(left, sizeof(cmd.data)) - 1;
+
+	while (left) {
+		size_t transfer_len = min(left, sizeof(cmd.data));
+
+		memset(&cmd, 0, sizeof(cmd));
+		cmd.blocks_left = cpu_to_le16(blocks_left);
+		memcpy(cmd.data, fw->data + done, transfer_len);
+
+		dev_dbg(&bcm43xx->pdev->dev,
+			"btbcmpci: sending ptb chunk; left: %zu\n", left);
+
+		skb = __hci_cmd_sync(bcm43xx->hdev, 0xfe0d, sizeof(cmd), &cmd,
+				     HCI_INIT_TIMEOUT);
+		if (IS_ERR(skb)) {
+			ret = PTR_ERR(skb);
+			dev_err(&bcm43xx->pdev->dev,
+				"btbcmpci: sending ptb failed (%d)", ret);
+			goto out;
+		}
+		kfree_skb(skb);
+
+		blocks_left--;
+		left -= transfer_len;
+		done += transfer_len;
+	}
+
+out:
+	release_firmware(fw);
+	return ret;
+}
+
+static int bcm43xx_hci_open(struct hci_dev *hdev)
+{
+	struct bcm43xx_data *bcm43xx = hci_get_drvdata(hdev);
+	int ret;
+
+	ret = bcm43xx_create_completion_ring(bcm43xx,
+					     &bcm43xx->hci_acl_ack_ring);
+	if (ret)
+		return ret;
+	ret = bcm43xx_create_completion_ring(bcm43xx,
+					     &bcm43xx->hci_acl_event_ring);
+	if (ret)
+		goto destroy_hci_acl_ack;
+	ret = bcm43xx_create_completion_ring(bcm43xx, &bcm43xx->sco_ack_ring);
+	if (ret)
+		goto destroy_hci_acl_event;
+	ret = bcm43xx_create_completion_ring(bcm43xx, &bcm43xx->sco_event_ring);
+	if (ret)
+		goto destroy_sco_ack;
+	dev_dbg(&bcm43xx->pdev->dev,
+		"all completion rings successfully created!\n");
+
+	ret = bcm43xx_create_transfer_ring(bcm43xx, &bcm43xx->hci_h2d_ring);
+	if (ret)
+		goto destroy_sco_event;
+	ret = bcm43xx_create_transfer_ring(bcm43xx, &bcm43xx->hci_d2h_ring);
+	if (ret)
+		goto destroy_hci_h2d;
+	ret = bcm43xx_create_transfer_ring(bcm43xx, &bcm43xx->sco_h2d_ring);
+	if (ret)
+		goto destroy_hci_d2h;
+	ret = bcm43xx_create_transfer_ring(bcm43xx, &bcm43xx->sco_d2h_ring);
+	if (ret)
+		goto destroy_sco_h2d;
+	ret = bcm43xx_create_transfer_ring(bcm43xx, &bcm43xx->acl_h2d_ring);
+	if (ret)
+		goto destroy_sco_d2h;
+	ret = bcm43xx_create_transfer_ring(bcm43xx, &bcm43xx->acl_d2h_ring);
+	if (ret)
+		goto destroy_acl_h2d;
+	dev_dbg(&bcm43xx->pdev->dev,
+		"all transfer rings successfully created!\n");
+
+	return 0;
+
+destroy_acl_h2d:
+	bcm43xx_destroy_transfer_ring(bcm43xx, &bcm43xx->acl_h2d_ring);
+destroy_sco_d2h:
+	bcm43xx_destroy_transfer_ring(bcm43xx, &bcm43xx->sco_d2h_ring);
+destroy_sco_h2d:
+	bcm43xx_destroy_transfer_ring(bcm43xx, &bcm43xx->sco_h2d_ring);
+destroy_hci_d2h:
+	bcm43xx_destroy_transfer_ring(bcm43xx, &bcm43xx->hci_h2d_ring);
+destroy_hci_h2d:
+	bcm43xx_destroy_transfer_ring(bcm43xx, &bcm43xx->hci_d2h_ring);
+destroy_sco_event:
+	bcm43xx_destroy_completion_ring(bcm43xx, &bcm43xx->sco_event_ring);
+destroy_sco_ack:
+	bcm43xx_destroy_completion_ring(bcm43xx, &bcm43xx->sco_ack_ring);
+destroy_hci_acl_event:
+	bcm43xx_destroy_completion_ring(bcm43xx, &bcm43xx->hci_acl_event_ring);
+destroy_hci_acl_ack:
+	bcm43xx_destroy_completion_ring(bcm43xx, &bcm43xx->hci_acl_ack_ring);
+
+	return ret;
+}
+
+static int bcm43xx_hci_close(struct hci_dev *hdev)
+{
+	struct bcm43xx_data *bcm43xx = hci_get_drvdata(hdev);
+
+	bcm43xx_destroy_transfer_ring(bcm43xx, &bcm43xx->acl_d2h_ring);
+	bcm43xx_destroy_transfer_ring(bcm43xx, &bcm43xx->acl_h2d_ring);
+	bcm43xx_destroy_transfer_ring(bcm43xx, &bcm43xx->sco_d2h_ring);
+	bcm43xx_destroy_transfer_ring(bcm43xx, &bcm43xx->sco_h2d_ring);
+	bcm43xx_destroy_transfer_ring(bcm43xx, &bcm43xx->hci_h2d_ring);
+	bcm43xx_destroy_transfer_ring(bcm43xx, &bcm43xx->hci_h2d_ring);
+
+	bcm43xx_destroy_completion_ring(bcm43xx, &bcm43xx->sco_event_ring);
+	bcm43xx_destroy_completion_ring(bcm43xx, &bcm43xx->sco_ack_ring);
+	bcm43xx_destroy_completion_ring(bcm43xx, &bcm43xx->hci_acl_event_ring);
+	bcm43xx_destroy_completion_ring(bcm43xx, &bcm43xx->hci_acl_ack_ring);
+
+	return 0;
+}
+
+static int bcm43xx_hci_setup(struct hci_dev *hdev)
+{
+	struct bcm43xx_data *bcm43xx = hci_get_drvdata(hdev);
+	int ret;
+
+	if (bcm43xx->hw->send_calibration) {
+		ret = bcm43xx->hw->send_calibration(bcm43xx);
+		if (ret)
+			return ret;
+	}
+
+	ret = bcm43xx_send_ptb(bcm43xx);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int bcm43xx_hci_send_frame(struct hci_dev *hdev, struct sk_buff *skb)
+{
+	struct bcm43xx_data *bcm43xx = hci_get_drvdata(hdev);
+	struct bcm43xx_transfer_ring *ring;
+	int ret;
+
+	switch (hci_skb_pkt_type(skb)) {
+	case HCI_COMMAND_PKT:
+		hdev->stat.cmd_tx++;
+		ring = &bcm43xx->hci_h2d_ring;
+		break;
+
+	case HCI_ACLDATA_PKT:
+		hdev->stat.acl_tx++;
+		ring = &bcm43xx->acl_h2d_ring;
+		break;
+
+	case HCI_SCODATA_PKT:
+		hdev->stat.sco_tx++;
+		ring = &bcm43xx->sco_h2d_ring;
+		break;
+
+	default:
+		return -EILSEQ;
+	}
+
+	ret = bcm43xx_enqueue(bcm43xx, ring, skb->data, skb->len, false);
+	if (ret < 0) {
+		hdev->stat.err_tx++;
+		return ret;
+	}
+
+	hdev->stat.byte_tx += skb->len;
+	kfree_skb(skb);
+	return ret;
+}
+
+static int bcm43xx_hci_set_bdaddr(struct hci_dev *hdev, const bdaddr_t *bdaddr)
+{
+	u8 bdaddr_swapped[6];
+	struct sk_buff *skb;
+	int i, err;
+
+	/* Unlike the regular BCM chips the address has to be swapped here */
+	for (i = 0; i < sizeof(bdaddr_swapped); ++i)
+		bdaddr_swapped[sizeof(bdaddr_swapped) - i - 1] = bdaddr->b[i];
+
+	skb = __hci_cmd_sync(hdev, 0xfc01, 6, bdaddr_swapped, HCI_INIT_TIMEOUT);
+	if (IS_ERR(skb)) {
+		err = PTR_ERR(skb);
+		bt_dev_err(hdev, "btbcmpci: Change address command failed (%d)",
+			   err);
+		return err;
+	}
+	kfree_skb(skb);
+
+	return 0;
+}
+
+static int bcm43xx_alloc_transfer_ring(struct bcm43xx_data *bcm43xx,
+				       struct bcm43xx_transfer_ring *ring)
+{
+	size_t entry_size;
+
+	spin_lock_init(&ring->lock);
+	if (ring->n_entries > BCM43XX_MAX_RING_SIZE)
+		return -EINVAL;
+	if (ring->virtual && ring->allow_wait)
+		return -EINVAL;
+	if (ring->payload_size % 4)
+		return -EINVAL;
+	if (ring->virtual)
+		return 0;
+
+	entry_size =
+		ring->payload_size + sizeof(struct bcm43xx_xfer_ring_entry);
+	ring->ring = dmam_alloc_coherent(&bcm43xx->pdev->dev,
+					 ring->n_entries * entry_size,
+					 &ring->ring_dma, GFP_KERNEL);
+	if (!ring->ring)
+		return -ENOMEM;
+
+	if (ring->allow_wait) {
+		ring->events = devm_kcalloc(&bcm43xx->pdev->dev,
+					    ring->n_entries,
+					    sizeof(*ring->events), GFP_KERNEL);
+		if (!ring->events)
+			return -ENOMEM;
+	}
+	return 0;
+}
+
+static int bcm43xx_alloc_completion_ring(struct bcm43xx_data *bcm43xx,
+					 struct bcm43xx_completion_ring *ring)
+{
+	size_t entry_size;
+
+	if (ring->n_entries > BCM43XX_MAX_RING_SIZE)
+		return -EINVAL;
+	if (ring->payload_size % 4)
+		return -EINVAL;
+
+	entry_size = ring->payload_size +
+		     sizeof(struct bcm43xx_completion_ring_entry);
+
+	ring->ring = dmam_alloc_coherent(&bcm43xx->pdev->dev,
+					 ring->n_entries * entry_size,
+					 &ring->ring_dma, GFP_KERNEL);
+	if (!ring->ring)
+		return -ENOMEM;
+	return 0;
+}
+
+static int bcm43xx_init_context(struct bcm43xx_data *bcm43xx)
+{
+	struct device *dev = &bcm43xx->pdev->dev;
+
+	bcm43xx->ctx = dmam_alloc_coherent(dev, sizeof(*bcm43xx->ctx),
+					   &bcm43xx->ctx_dma, GFP_KERNEL);
+	if (!bcm43xx->ctx)
+		return -ENOMEM;
+	memset(bcm43xx->ctx, 0, sizeof(*bcm43xx->ctx));
+
+	bcm43xx->ring_state =
+		dmam_alloc_coherent(dev, sizeof(*bcm43xx->ring_state),
+				    &bcm43xx->ring_state_dma, GFP_KERNEL);
+	if (!bcm43xx->ring_state)
+		return -ENOMEM;
+	memset(bcm43xx->ring_state, 0, sizeof(*bcm43xx->ring_state));
+
+	bcm43xx->ctx->version = cpu_to_le16(1);
+	bcm43xx->ctx->size = cpu_to_le16(sizeof(*bcm43xx->ctx));
+	bcm43xx->ctx->enabled_caps = cpu_to_le16(2);
+
+	// TODO: do we actually care about the contents here?
+	dmam_alloc_coherent(&bcm43xx->pdev->dev, PAGE_SIZE,
+			    &bcm43xx->ctx->per_info_addr, GFP_KERNEL);
+
+	bcm43xx->ctx->xfer_ring_heads_addr =
+		bcm43xx->ring_state_dma +
+		offsetof(struct bcm43xx_ring_state, xfer_ring_head);
+	bcm43xx->ctx->xfer_ring_tails_addr =
+		bcm43xx->ring_state_dma +
+		offsetof(struct bcm43xx_ring_state, xfer_ring_tail);
+	bcm43xx->ctx->completion_ring_heads_addr =
+		bcm43xx->ring_state_dma +
+		offsetof(struct bcm43xx_ring_state, completion_ring_head);
+	bcm43xx->ctx->completion_ring_tails_addr =
+		bcm43xx->ring_state_dma +
+		offsetof(struct bcm43xx_ring_state, completion_ring_tail);
+
+	bcm43xx->ctx->n_completion_rings =
+		cpu_to_le16(BCM43XX_N_COMPLETION_RINGS);
+	bcm43xx->ctx->n_xfer_rings = cpu_to_le16(BCM43XX_N_TRANSFER_RINGS);
+
+	bcm43xx->ctx->control_completion_ring_addr =
+		cpu_to_le64(bcm43xx->control_ack_ring.ring_dma);
+	bcm43xx->ctx->control_completion_ring_n_entries =
+		cpu_to_le16(bcm43xx->control_ack_ring.n_entries);
+	bcm43xx->ctx->control_completion_ring_doorbell = cpu_to_le16(0xffff);
+	bcm43xx->ctx->control_completion_ring_msi = 0;
+	bcm43xx->ctx->control_completion_ring_header_size = 0;
+	bcm43xx->ctx->control_completion_ring_footer_size = 0;
+
+	bcm43xx->ctx->control_xfer_ring_addr =
+		cpu_to_le64(bcm43xx->control_h2d_ring.ring_dma);
+	bcm43xx->ctx->control_xfer_ring_n_entries =
+		cpu_to_le16(bcm43xx->control_h2d_ring.n_entries);
+	bcm43xx->ctx->control_xfer_ring_doorbell =
+		cpu_to_le16(bcm43xx->control_h2d_ring.doorbell);
+	bcm43xx->ctx->control_xfer_ring_msi = 0;
+	bcm43xx->ctx->control_xfer_ring_header_size = 0;
+	bcm43xx->ctx->control_xfer_ring_footer_size =
+		bcm43xx->control_h2d_ring.payload_size / 4;
+
+	return 0;
+}
+
+static int bcm43xx_prepare_rings(struct bcm43xx_data *bcm43xx)
+{
+	int ret;
+
+	/*
+	 * Even though many of these settings appear to be configurable
+	 * when sending the "create ring" messages most of these are
+	 * actually hardcoded in some (and quite possibly all) firmware versions
+	 * and changing them on the host has no effect.
+	 * Specifically, this applies to at least the doorbells, the transfer
+	 * and completion ring ids and their mapping (e.g. both HCI and ACL
+	 * entries will always be queued in completion rings 1 and 2 no matter
+	 * what we configure here).
+	 */
+	bcm43xx->control_ack_ring.ring_id = BCM43XX_ACK_RING_CONTROL;
+	bcm43xx->control_ack_ring.n_entries = 128;
+	bcm43xx->control_ack_ring.transfer_rings =
+		BIT(BCM43XX_XFER_RING_CONTROL);
+
+	bcm43xx->hci_acl_ack_ring.ring_id = BCM43XX_ACK_RING_HCI_ACL;
+	bcm43xx->hci_acl_ack_ring.n_entries = 256;
+	bcm43xx->hci_acl_ack_ring.transfer_rings =
+		BIT(BCM43XX_XFER_RING_HCI_H2D) | BIT(BCM43XX_XFER_RING_ACL_H2D);
+	bcm43xx->hci_acl_ack_ring.delay = 1000;
+
+	bcm43xx->hci_acl_event_ring.ring_id = BCM43XX_EVENT_RING_HCI_ACL;
+	// TODO: this is just a max-sized HCI frame, but small for ACL?
+	bcm43xx->hci_acl_event_ring.payload_size = 4 * 66;
+	bcm43xx->hci_acl_event_ring.n_entries = 256;
+	bcm43xx->hci_acl_event_ring.transfer_rings =
+		BIT(BCM43XX_XFER_RING_HCI_D2H) | BIT(BCM43XX_XFER_RING_ACL_D2H);
+	bcm43xx->hci_acl_event_ring.delay = 1000;
+
+	bcm43xx->sco_ack_ring.ring_id = BCM43XX_ACK_RING_SCO;
+	bcm43xx->sco_ack_ring.n_entries = 128;
+	bcm43xx->sco_ack_ring.transfer_rings = BIT(BCM43XX_XFER_RING_SCO_H2D);
+
+	bcm43xx->sco_event_ring.ring_id = BCM43XX_EVENT_RING_SCO;
+	// TODO: this is just a max-sized SCO frame
+	bcm43xx->sco_event_ring.payload_size = 4 * 66;
+	bcm43xx->sco_event_ring.n_entries = 128;
+	bcm43xx->sco_event_ring.transfer_rings = BIT(BCM43XX_XFER_RING_SCO_D2H);
+
+	bcm43xx->control_h2d_ring.ring_id = BCM43XX_XFER_RING_CONTROL;
+	bcm43xx->control_h2d_ring.doorbell = BCM43XX_DOORBELL_CONTROL;
+	bcm43xx->control_h2d_ring.payload_size = BCM43XX_CIPC_CONTROL_MSG_SIZE;
+	bcm43xx->control_h2d_ring.completion_ring = BCM43XX_ACK_RING_CONTROL;
+	bcm43xx->control_h2d_ring.allow_wait = true;
+	bcm43xx->control_h2d_ring.n_entries = 128;
+
+	bcm43xx->hci_h2d_ring.ring_id = BCM43XX_XFER_RING_HCI_H2D;
+	bcm43xx->hci_h2d_ring.doorbell = BCM43XX_DOORBELL_HCI_H2D;
+	// TODO: this is just a max-sized HCI frame, what about ACL though?
+	bcm43xx->hci_h2d_ring.payload_size = 4 * 66;
+	bcm43xx->hci_h2d_ring.completion_ring = BCM43XX_ACK_RING_HCI_ACL;
+	bcm43xx->hci_h2d_ring.n_entries = 128;
+
+	bcm43xx->hci_d2h_ring.ring_id = BCM43XX_XFER_RING_HCI_D2H;
+	bcm43xx->hci_d2h_ring.doorbell = BCM43XX_DOORBELL_HCI_D2H;
+	bcm43xx->hci_d2h_ring.completion_ring = BCM43XX_EVENT_RING_HCI_ACL;
+	bcm43xx->hci_d2h_ring.virtual = true;
+	bcm43xx->hci_d2h_ring.n_entries = 128;
+
+	bcm43xx->sco_h2d_ring.ring_id = BCM43XX_XFER_RING_SCO_H2D;
+	bcm43xx->sco_h2d_ring.doorbell = BCM43XX_DOORBELL_SCO;
+	// TODO: this is just a max-sized SCO frame
+	bcm43xx->sco_h2d_ring.payload_size = 4 * 66;
+	bcm43xx->sco_h2d_ring.completion_ring = BCM43XX_ACK_RING_SCO;
+	bcm43xx->sco_h2d_ring.sync = true;
+	bcm43xx->sco_h2d_ring.n_entries = 128;
+
+	bcm43xx->sco_d2h_ring.ring_id = BCM43XX_XFER_RING_SCO_D2H;
+	bcm43xx->sco_d2h_ring.doorbell = BCM43XX_DOORBELL_SCO;
+	bcm43xx->sco_d2h_ring.completion_ring = BCM43XX_EVENT_RING_SCO;
+	bcm43xx->sco_d2h_ring.virtual = true;
+	bcm43xx->sco_d2h_ring.sync = true;
+	bcm43xx->sco_d2h_ring.n_entries = 128;
+
+	bcm43xx->acl_h2d_ring.ring_id = BCM43XX_XFER_RING_ACL_H2D;
+	bcm43xx->acl_h2d_ring.doorbell = BCM43XX_DOORBELL_ACL_H2D;
+	// TODO: this almost fits a max-size ACL frame
+	bcm43xx->acl_h2d_ring.payload_size = 4 * 252;
+	bcm43xx->acl_h2d_ring.completion_ring = BCM43XX_ACK_RING_HCI_ACL;
+	bcm43xx->acl_h2d_ring.n_entries = 128;
+
+	bcm43xx->acl_d2h_ring.ring_id = BCM43XX_XFER_RING_ACL_D2H;
+	bcm43xx->acl_d2h_ring.doorbell = BCM43XX_DOORBELL_ACL_D2H;
+	bcm43xx->acl_d2h_ring.completion_ring = BCM43XX_EVENT_RING_HCI_ACL;
+	bcm43xx->acl_d2h_ring.virtual = true;
+	bcm43xx->acl_d2h_ring.n_entries = 128;
+
+	/*
+	 * no need for any cleanup since this is only called from _probe
+	 * and only devres-managed allocations are used
+	 */
+	ret = bcm43xx_alloc_transfer_ring(bcm43xx, &bcm43xx->control_h2d_ring);
+	if (ret)
+		return ret;
+	ret = bcm43xx_alloc_transfer_ring(bcm43xx, &bcm43xx->hci_h2d_ring);
+	if (ret)
+		return ret;
+	ret = bcm43xx_alloc_transfer_ring(bcm43xx, &bcm43xx->hci_d2h_ring);
+	if (ret)
+		return ret;
+	ret = bcm43xx_alloc_transfer_ring(bcm43xx, &bcm43xx->sco_h2d_ring);
+	if (ret)
+		return ret;
+	ret = bcm43xx_alloc_transfer_ring(bcm43xx, &bcm43xx->sco_d2h_ring);
+	if (ret)
+		return ret;
+	ret = bcm43xx_alloc_transfer_ring(bcm43xx, &bcm43xx->acl_h2d_ring);
+	if (ret)
+		return ret;
+	ret = bcm43xx_alloc_transfer_ring(bcm43xx, &bcm43xx->acl_d2h_ring);
+	if (ret)
+		return ret;
+
+	ret = bcm43xx_alloc_completion_ring(bcm43xx,
+					    &bcm43xx->control_ack_ring);
+	if (ret)
+		return ret;
+	ret = bcm43xx_alloc_completion_ring(bcm43xx,
+					    &bcm43xx->hci_acl_ack_ring);
+	if (ret)
+		return ret;
+	ret = bcm43xx_alloc_completion_ring(bcm43xx,
+					    &bcm43xx->hci_acl_event_ring);
+	if (ret)
+		return ret;
+	ret = bcm43xx_alloc_completion_ring(bcm43xx, &bcm43xx->sco_ack_ring);
+	if (ret)
+		return ret;
+	ret = bcm43xx_alloc_completion_ring(bcm43xx, &bcm43xx->sco_event_ring);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int bcm43xx_setup_msi(struct bcm43xx_data *bcm43xx)
+{
+	struct msi_msg msi_msg;
+	int ret;
+
+	ret = irq_chip_compose_msi_msg(irq_get_irq_data(bcm43xx->irq),
+				       &msi_msg);
+	if (ret)
+		return ret;
+
+	iowrite32(msi_msg.address_lo, bcm43xx->bar0 + BCM43XX_BAR0_MSI_ADDR_LO);
+	iowrite32(msi_msg.address_hi, bcm43xx->bar0 + BCM43XX_BAR0_MSI_ADDR_HI);
+
+	return 0;
+}
+
+static int bcm43xx_boot(struct bcm43xx_data *bcm43xx)
+{
+	u32 bootstage;
+	const struct firmware *fw;
+	void *bfr;
+	dma_addr_t fw_dma;
+	int ret = 0;
+
+	fw = bcm43xx_request_blob(bcm43xx, "bin");
+	if (!fw)
+		return -ENOENT;
+
+	bfr = dma_alloc_coherent(&bcm43xx->pdev->dev, fw->size, &fw_dma,
+				 GFP_KERNEL);
+	if (!bfr) {
+		ret = -ENOMEM;
+		goto out_release_fw;
+	}
+
+	memcpy(bfr, fw->data, fw->size);
+
+	/* we're behind an IOMMU and can just allow the entire IOVA space */
+	// TODO: double check if this is always correct; it probably is since we don't call dma_set_mask_and_coherent
+	iowrite32(0, bcm43xx->bar0 + BCM43XX_BAR0_HOST_WINDOW_LO);
+	iowrite32(0, bcm43xx->bar0 + BCM43XX_BAR0_HOST_WINDOW_HI);
+	iowrite32(0xffffffff, bcm43xx->bar0 + BCM43XX_BAR0_HOST_WINDOW_SIZE);
+
+	iowrite32(lower_32_bits(fw_dma), bcm43xx->bar2 + BCM43XX_BAR2_FW_LO);
+	iowrite32(upper_32_bits(fw_dma), bcm43xx->bar2 + BCM43XX_BAR2_FW_HI);
+	iowrite32(fw->size, bcm43xx->bar2 + BCM43XX_BAR2_FW_SIZE);
+	iowrite32(0, bcm43xx->bar0 + BCM43XX_BAR0_FW_DOORBELL);
+
+	ret = wait_for_completion_interruptible_timeout(&bcm43xx->event, 1000);
+	if (ret == 0) {
+		ret = -ETIMEDOUT;
+		goto out_dma_free;
+	} else if (ret < 0) {
+		goto out_dma_free;
+	}
+
+	bootstage = ioread32(bcm43xx->bar2 + BCM43XX_BAR2_BOOTSTAGE);
+	if (bootstage != 2) {
+		dev_err(&bcm43xx->pdev->dev, "boostage (%x) != 2\n", bootstage);
+		ret = -ENXIO;
+		goto out_dma_free;
+	}
+
+	dev_dbg(&bcm43xx->pdev->dev, "firmware has booted (stage = %x)\n",
+		bootstage);
+	ret = 0;
+
+out_dma_free:
+	dma_free_coherent(&bcm43xx->pdev->dev, fw->size, bfr, fw_dma);
+out_release_fw:
+	release_firmware(fw);
+	return ret;
+}
+
+static int bcm43xx_setup_rti(struct bcm43xx_data *bcm43xx)
+{
+	u32 rti_status;
+	struct msi_msg msi_msg;
+	int ret;
+
+	ret = irq_chip_compose_msi_msg(irq_get_irq_data(bcm43xx->irq),
+				       &msi_msg);
+	if (ret)
+		return ret;
+
+	/* setup and start RTI (?) */
+	iowrite32(msi_msg.address_lo,
+		  bcm43xx->bar2 + BCM43XX_BAR2_RTI_MSI_ADDR_LO);
+	iowrite32(msi_msg.address_hi,
+		  bcm43xx->bar2 + BCM43XX_BAR2_RTI_MSI_ADDR_HI);
+	iowrite32(msi_msg.data, bcm43xx->bar2 + BCM43XX_BAR2_RTI_MSI_DATA);
+	iowrite32(1, bcm43xx->bar0 + BCM43XX_BAR0_RTI_CONTROL);
+
+	ret = wait_for_completion_interruptible_timeout(&bcm43xx->event, 1000);
+	if (ret == 0) {
+		dev_err(&bcm43xx->pdev->dev,
+			"timed out while waiting for RTI to transition to state 1");
+		return -ETIMEDOUT;
+	} else if (ret < 0) {
+		return ret;
+	}
+
+	rti_status = ioread32(bcm43xx->bar2 + BCM43XX_BAR2_RTI_STATUS);
+	if (rti_status != 1) {
+		dev_err(&bcm43xx->pdev->dev, "RTI did not ack state 1 (%d)\n",
+			rti_status);
+		return -ENODEV;
+	}
+	dev_dbg(&bcm43xx->pdev->dev, "RTI is in state 1\n");
+
+	/* allow access to the entire IOVA space again */
+	iowrite32(0, bcm43xx->bar2 + BCM43XX_BAR2_RTI_WINDOW_LO);
+	iowrite32(0, bcm43xx->bar2 + BCM43XX_BAR2_RTI_WINDOW_HI);
+	iowrite32(0xffffffff, bcm43xx->bar2 + BCM43XX_BAR2_RTI_WINDOW_SIZE);
+
+	/* setup "Converged IPC" context */
+	iowrite32(lower_32_bits(bcm43xx->ctx_dma),
+		  bcm43xx->bar2 + BCM43XX_BAR2_CONTEXT_ADDR_LO);
+	iowrite32(upper_32_bits(bcm43xx->ctx_dma),
+		  bcm43xx->bar2 + BCM43XX_BAR2_CONTEXT_ADDR_HI);
+	iowrite32(2, bcm43xx->bar0 + BCM43XX_BAR0_RTI_CONTROL);
+
+	ret = wait_for_completion_interruptible_timeout(&bcm43xx->event, 1000);
+	if (ret == 0) {
+		dev_err(&bcm43xx->pdev->dev,
+			"timed out while waiting for RTI to transition to state 2");
+		return -ETIMEDOUT;
+	} else if (ret < 0) {
+		return ret;
+	}
+
+	rti_status = ioread32(bcm43xx->bar2 + BCM43XX_BAR2_RTI_STATUS);
+	if (rti_status != 2) {
+		dev_err(&bcm43xx->pdev->dev, "RTI did not ack state 2 (%d)\n",
+			rti_status);
+		return -ENODEV;
+	}
+
+	dev_dbg(&bcm43xx->pdev->dev,
+		"RTI is in state 2; control pipe is ready\n");
+	bcm43xx->control_ack_ring.enabled = true;
+
+	return 0;
+}
+
+static int bcm43xx_parse_otp_board_params(struct bcm43xx_data *bcm43xx,
+					  char tag, const char *val, size_t len)
+{
+	if (tag != 'V')
+		return 0;
+
+	strscpy(bcm43xx->vendor, val, len + 1);
+	return 0;
+}
+
+static int bcm43xx_parse_otp_chip_params(struct bcm43xx_data *bcm43xx, char tag,
+					 const char *val, size_t len)
+{
+	size_t idx = 0;
+
+	if (tag != 's')
+		return 0;
+
+	/* 
+	 * this won't write out of bounds since len < BCM43XX_OTP_MAX_PARAM_LEN
+	 * and sizeof(bcm43xx->stepping) = BCM43XX_OTP_MAX_PARAM_LEN
+	 */
+	while (len != 0) {
+		bcm43xx->stepping[idx] = tolower(val[idx]);
+		if (val[idx] == '\0')
+			return 0;
+
+		idx++;
+		len--;
+	}
+
+	bcm43xx->stepping[idx] = '\0';
+	return 0;
+}
+
+static int bcm43xx_parse_opt_str(struct bcm43xx_data *bcm43xx, const u8 *str,
+				 int (*parse_arg)(struct bcm43xx_data *, char,
+						  const char *, size_t))
+{
+	const char *p;
+	int ret;
+
+	p = skip_spaces(str);
+	while (*p) {
+		char tag = *p++;
+		const char *end;
+		size_t len;
+
+		if (*p++ != '=') /* implicit NUL check */
+			return -EINVAL;
+
+		/* *p might be NUL here, if so end == p and len == 0 */
+		end = strchrnul(p, ' ');
+		len = end - p;
+
+		/* leave 1 byte for NUL in destination string */
+		if (len > (BCM43XX_OTP_MAX_PARAM_LEN - 1))
+			return -EINVAL;
+
+		/* Copy len characters plus a NUL terminator */
+		ret = parse_arg(bcm43xx, tag, p, len);
+		if (ret)
+			return ret;
+
+		/* Skip to next arg, if any */
+		p = skip_spaces(end);
+	}
+
+	return 0;
+}
+
+static int bcm43xx_parse_otp_sys_vendor(struct bcm43xx_data *bcm43xx, u8 *otp,
+					size_t size)
+{
+	int idx = 4;
+	const char *chip_params;
+	const char *board_params;
+	int ret;
+
+	/* 4-byte header and two empty strings */
+	if (size < 6)
+		return -EINVAL;
+
+	if (get_unaligned_le32(otp) != BCM43XX_OTP_VENDOR_HDR)
+		return -EINVAL;
+
+	chip_params = &otp[idx];
+
+	/* Skip first string, including terminator */
+	idx += strnlen(chip_params, size - idx) + 1;
+	if (idx >= size)
+		return -EINVAL;
+
+	board_params = &otp[idx];
+
+	/* Skip to terminator of second string */
+	idx += strnlen(board_params, size - idx);
+	if (idx >= size)
+		return -EINVAL;
+
+	/* At this point both strings are guaranteed NUL-terminated */
+	dev_dbg(&bcm43xx->pdev->dev,
+		"OTP: chip_params='%s' board_params='%s'\n", chip_params,
+		board_params);
+
+	ret = bcm43xx_parse_opt_str(bcm43xx, chip_params,
+				    bcm43xx_parse_otp_chip_params);
+	if (ret)
+		return ret;
+
+	ret = bcm43xx_parse_opt_str(bcm43xx, board_params,
+				    bcm43xx_parse_otp_board_params);
+	if (ret)
+		return ret;
+
+	dev_dbg(&bcm43xx->pdev->dev, "OTP: stepping=%s, vendor=%s\n",
+		bcm43xx->stepping, bcm43xx->vendor);
+
+	if (!bcm43xx->stepping[0] || !bcm43xx->vendor[0])
+		return -EINVAL;
+
+	return 0;
+}
+
+static int bcm43xx_read_otp(struct bcm43xx_data *bcm43xx)
+{
+	u8 otp[BCM43XX_OTP_SIZE];
+	int i, ret;
+
+	for (i = 0; i < BCM43XX_OTP_SIZE; ++i)
+		otp[i] = ioread8(bcm43xx->bar0 + BCM43XX_BAR0_OTP_OFFSET + i);
+
+	i = 0;
+	while (i < (BCM43XX_OTP_SIZE - 1)) {
+		u8 type = otp[i];
+		u8 length = otp[i + 1];
+
+		if (type == 0)
+			break;
+
+		if ((i + 2 + length) > BCM43XX_OTP_SIZE)
+			break;
+
+		switch (type) {
+		case BCM43XX_OTP_SYS_VENDOR:
+			dev_dbg(&bcm43xx->pdev->dev,
+				"OTP @ 0x%x (%d): SYS_VENDOR", i, length);
+			ret = bcm43xx_parse_otp_sys_vendor(bcm43xx, &otp[i + 2],
+							   length);
+			break;
+		case BCM43XX_OTP_CIS:
+			dev_dbg(&bcm43xx->pdev->dev,
+				"OTP @ 0x%x (%d): BCM43XX_CIS", i, length);
+			break;
+		default:
+			dev_dbg(&bcm43xx->pdev->dev, "OTP @ 0x%x (%d): unknown",
+				i, length);
+			break;
+		}
+
+		i += 2 + length;
+	}
+
+	return ret;
+}
+
+static int bcm43xx_init_cfg(struct bcm43xx_data *bcm43xx)
+{
+	int ret;
+	u32 ctrl;
+
+	ret = pci_write_config_dword(bcm43xx->pdev,
+				     BCM43XX_PCIECFG_BAR0_WINDOW0,
+				     bcm43xx->hw->bar0_window0);
+	if (ret)
+		return ret;
+
+	ret = pci_write_config_dword(bcm43xx->pdev,
+				     BCM43XX_PCIECFG_BAR0_WINDOW1,
+				     bcm43xx->hw->bar0_window1);
+	if (ret)
+		return ret;
+
+	ret = pci_write_config_dword(bcm43xx->pdev,
+				     BCM43XX_PCIECFG_BAR0_WINDOW4,
+				     BCM43XX_PCIECFG_BAR0_WINDOW4_DEFAULT);
+	if (ret)
+		return ret;
+
+	if (bcm43xx->hw->has_bar0_window5) {
+		ret = pci_write_config_dword(bcm43xx->pdev,
+					     BCM43XX_PCIECFG_BAR0_WINDOW5,
+					     bcm43xx->hw->bar0_window5);
+		if (ret)
+			return ret;
+	}
+
+	ret = pci_write_config_dword(bcm43xx->pdev, BCM43XX_PCIECFG_BAR2_WINDOW,
+				     BCM43XX_PCIECFG_BAR2_WINDOW_DEFAULT);
+	if (ret)
+		return ret;
+
+	ret = pci_read_config_dword(bcm43xx->pdev, BCM43XX_PCIECFG_UNK_CTRL,
+				    &ctrl);
+	if (ret)
+		return ret;
+
+	// TODO: 19 and 16 are probably M2M and SS reset
+	if (!bcm43xx->hw->m2m_reset_on_ss_reset_disabled)
+		ctrl &= ~BIT(19); // BIT(19) = M2M reset?
+	ctrl |= BIT(16);
+
+	return pci_write_config_dword(bcm43xx->pdev, BCM43XX_PCIECFG_UNK_CTRL,
+				      ctrl);
+}
+
+static int bcm43xx_probe_of(struct bcm43xx_data *bcm43xx)
+{
+	struct device_node *np = bcm43xx->pdev->dev.of_node;
+
+	if (!np)
+		return -ENOENT;
+
+	if (of_property_read_string(np, "brcm,board-type",
+				    &bcm43xx->board_type))
+		return -ENOENT;
+
+	bcm43xx->taurus_beamforming_cal_blob =
+		of_get_property(np, "brcm,taurus-bf-cal-blob",
+				&bcm43xx->taurus_beamforming_cal_size);
+	bcm43xx->taurus_cal_blob = of_get_property(np, "brcm,taurus-cal-blob",
+						   &bcm43xx->taurus_cal_size);
+
+	return 0;
+}
+
+static int bcm43xx_probe_acpi(struct bcm43xx_data *bcm43xx)
+{
+	const union acpi_object *o;
+	struct device *dev = &bcm43xx->pdev->dev;
+	struct acpi_device *adev = ACPI_COMPANION(dev);
+
+	if (!adev)
+		return -ENOENT;
+
+	if (!ACPI_FAILURE(acpi_dev_get_property(adev, "module-instance",
+						ACPI_TYPE_STRING, &o))) {
+		dev_dbg(dev, "ACPI module-instance=%s\n", o->string.pointer);
+		bcm43xx->board_type = devm_kasprintf(
+			dev, GFP_KERNEL, "apple,%s", o->string.pointer);
+	} else {
+		return -ENOENT;
+	}
+
+	return 0;
+}
+
+static const struct bcm43xx_hw bcm43xx_hw_variants[];
+
+static int bcm43xx_probe(struct pci_dev *pdev, const struct pci_device_id *id)
+{
+	struct bcm43xx_data *bcm43xx;
+	struct hci_dev *hdev;
+	int ret;
+
+	bcm43xx = devm_kzalloc(&pdev->dev, sizeof(*bcm43xx), GFP_KERNEL);
+	if (!bcm43xx)
+		return -ENOMEM;
+
+	bcm43xx->pdev = pdev;
+	bcm43xx->hw = &bcm43xx_hw_variants[id->driver_data];
+	init_completion(&bcm43xx->event);
+
+	ret = bcm43xx_prepare_rings(bcm43xx);
+	if (ret)
+		return ret;
+
+	ret = bcm43xx_init_context(bcm43xx);
+	if (ret)
+		return ret;
+
+	if (pdev->dev.of_node)
+		ret = bcm43xx_probe_of(bcm43xx);
+	else
+		ret = bcm43xx_probe_acpi(bcm43xx);
+	if (ret)
+		return ret;
+
+	ret = pci_enable_device(pdev);
+	if (ret)
+		return ret;
+	pci_set_master(pdev);
+
+	ret = bcm43xx_init_cfg(bcm43xx);
+	if (ret)
+		return ret;
+
+	bcm43xx->bar0 = pcim_iomap(pdev, 0, 0);
+	if (!bcm43xx->bar0)
+		return -EBUSY;
+	bcm43xx->bar2 = pcim_iomap(pdev, 2, 0);
+	if (!bcm43xx->bar2)
+		return -EBUSY;
+
+	ret = bcm43xx_read_otp(bcm43xx);
+	if (ret)
+		return ret;
+
+	// TODO: check if legacy irqs also work
+	ret = pci_alloc_irq_vectors(pdev, 1, 1, PCI_IRQ_MSI);
+	if (ret < 0)
+		return -ENODEV;
+
+	bcm43xx->irq = pci_irq_vector(pdev, 0);
+	if (bcm43xx->irq <= 0)
+		return -ENODEV;
+
+	ret = devm_request_irq(&pdev->dev, bcm43xx->irq, bcm43xx_irq, 0,
+			       "bcm43xx", bcm43xx);
+	if (ret)
+		return ret;
+
+	hdev = hci_alloc_dev();
+	if (!hdev)
+		return -ENOMEM;
+	ret = devm_add_action_or_reset(&pdev->dev,
+				       (void (*)(void *))hci_free_dev, hdev);
+	if (ret)
+		return ret;
+
+	bcm43xx->hdev = hdev;
+
+	hdev->bus = HCI_PCI;
+	hdev->dev_type = HCI_PRIMARY;
+	hdev->open = bcm43xx_hci_open;
+	hdev->close = bcm43xx_hci_close;
+	hdev->send = bcm43xx_hci_send_frame;
+	hdev->set_bdaddr = bcm43xx_hci_set_bdaddr;
+	hdev->setup = bcm43xx_hci_setup;
+
+	/* non-DT devices have the address stored inside a ROM */
+	if (pdev->dev.of_node)
+		set_bit(HCI_QUIRK_USE_BDADDR_PROPERTY, &hdev->quirks);
+
+	pci_set_drvdata(pdev, bcm43xx);
+	hci_set_drvdata(hdev, bcm43xx);
+	SET_HCIDEV_DEV(hdev, &pdev->dev);
+
+	ret = bcm43xx_setup_msi(bcm43xx);
+	if (ret)
+		return ret;
+
+	ret = bcm43xx_boot(bcm43xx);
+	if (ret)
+		return ret;
+
+	ret = bcm43xx_setup_rti(bcm43xx);
+	if (ret)
+		return ret;
+
+	ret = hci_register_dev(hdev);
+	if (ret)
+		return ret;
+	return devm_add_action_or_reset(
+		&pdev->dev, (void (*)(void *))hci_unregister_dev, hdev);
+}
+
+static const struct bcm43xx_hw bcm43xx_hw_variants[] = {
+	[BCM4377] = {
+		.name = "4377",
+		.bar0_window0 = 0x1800b000,
+		.bar0_window1 = 0x1810c000,
+		.has_bar0_window5 = false,
+		.m2m_reset_on_ss_reset_disabled = false,
+		.send_calibration = NULL,
+	},
+
+	[BCM4378] = {
+		.name = "4378",
+		.bar0_window0 = 0x18002000,
+		.bar0_window1 = 0x1810a000,
+		.bar0_window5 = 0x18107000,
+		.has_bar0_window5 = true,
+		.m2m_reset_on_ss_reset_disabled = false,
+		.send_calibration = bcm43xx_bcm4378_send_calibration,
+	},
+
+	[BCM4387]= {
+		.name = "4387",
+		.bar0_window0 = 0x18002000,
+		.bar0_window1 = 0x18109000,
+		.bar0_window5 = 0x18106000,
+		.has_bar0_window5 = true,
+		.m2m_reset_on_ss_reset_disabled = true,
+		.send_calibration = bcm43xx_bcm4387_send_calibration,
+	},
+};
+
+#define BCM43XX_DEVID_ENTRY(id)                                             \
+	{                                                                   \
+		PCI_VENDOR_ID_BROADCOM, BCM##id##_DEVICE_ID, PCI_ANY_ID,    \
+			PCI_ANY_ID, PCI_CLASS_NETWORK_OTHER << 8, 0xffff00, \
+			BCM##id                                             \
+	}
+
+static const struct pci_device_id bcm43xx_devid_table[] = {
+	BCM43XX_DEVID_ENTRY(4377),
+	BCM43XX_DEVID_ENTRY(4378),
+	BCM43XX_DEVID_ENTRY(4387),
+	{},
+};
+MODULE_DEVICE_TABLE(pci, bcm43xx_devid_table);
+
+static struct pci_driver bcm43xx_pci_driver = {
+	.node = {},
+	.name = "bcm43xx",
+	.id_table = bcm43xx_devid_table,
+	.probe = bcm43xx_probe,
+};
+module_pci_driver(bcm43xx_pci_driver);
+
+MODULE_AUTHOR("Sven Peter <sven@svenpeter.dev>");
+MODULE_DESCRIPTION("Bluetooth support for Broadcom 43XX PCIe devices");
+MODULE_LICENSE("GPL");
+MODULE_FIRMWARE("brcmbt*.bin");
+MODULE_FIRMWARE("brcmbt*.ptb");
